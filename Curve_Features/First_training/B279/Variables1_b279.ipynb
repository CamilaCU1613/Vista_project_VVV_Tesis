{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b134609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.optimize import curve_fit\n",
    "from astropy.timeseries import LombScargle\n",
    "from scipy.signal import find_peaks\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da2d53dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: PVariablesb279.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       4   ()      \n",
      "  1  KS_ALE        1 ImageHDU         7   (1280954,)   float64   \n",
      "  2  EKS_ALE       1 ImageHDU         8   (68, 100000)   float64   \n",
      "  3  KS_PV         1 ImageHDU         8   (68, 181)   float64   \n",
      "  4  EKS_PV        1 ImageHDU         8   (68, 181)   float64   \n"
     ]
    }
   ],
   "source": [
    "archivo = fits.open('TCampo_b279.fits')\n",
    "archivo1 = fits.open('PVariablesb279.fits')\n",
    "HJD=archivo[1].data\n",
    "Error=archivo1[4].data\n",
    "Ks=archivo1[3].data\n",
    "archivo1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5eb2fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_nan(error, ks, HJD):\n",
    "    indices_validos = ~np.isnan(ks)\n",
    "    error_filtrado = [error[i] for i in range(len(ks)) if indices_validos[i]]\n",
    "    ks_filtrado = [ks[i] for i in range(len(ks)) if indices_validos[i]]\n",
    "    HJD_filtrado = [HJD[i] for i in range(len(ks)) if indices_validos[i]]\n",
    "    return error_filtrado, ks_filtrado, np.round(HJD_filtrado,8)\n",
    "\n",
    "ks_nan=[]\n",
    "error_nan=[]\n",
    "HJD_na=[]\n",
    "y=0\n",
    "while y<len(Ks):\n",
    "    error_filtrado, ks_filtrado, HJD_filtrado = eliminar_nan(Error[y], Ks[y], HJD-2400000)\n",
    "    ks_nan.append(ks_filtrado)\n",
    "    error_nan.append(error_filtrado)\n",
    "    HJD_na.append(HJD_filtrado)\n",
    "    y+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b945569",
   "metadata": {},
   "source": [
    "# Variables Periodicas y LPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f546da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre el archivo de texto en modo lectura\n",
    "with open('B279.txt', 'r') as file:\n",
    "    # Lee cada línea del archivo\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Inicializa una lista vacía para almacenar los elementos de la primera columna\n",
    "posibles_variables = []\n",
    "\n",
    "# Itera sobre cada línea del archivo\n",
    "for line in lines:\n",
    "    # Divide la línea en columnas separadas por un espacio en blanco\n",
    "    columnas = line.split()\n",
    "    # Añade el primer elemento (primera columna) a la lista primera_columna\n",
    "    posibles_variables.append(columnas[0])\n",
    "    \n",
    "# Abre el archivo de texto en modo lectura\n",
    "with open('var_per', 'r') as file:\n",
    "    # Lee cada línea del archivo\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Inicializa una lista vacía para almacenar los elementos de la primera columna\n",
    "periodicas_variables = []\n",
    "periodos_periodicas = []\n",
    "# Itera sobre cada línea del archivo\n",
    "for line in lines:\n",
    "    # Divide la línea en columnas separadas por un espacio en blanco\n",
    "    columnas = line.split()\n",
    "    # Añade el primer elemento (primera columna) a la lista primera_columna\n",
    "    periodicas_variables.append(columnas[0])\n",
    "    periodos_periodicas.append(float(columnas[1]))\n",
    "    \n",
    "\n",
    "# Extraer los números después de \"Datosb279\" usando list comprehension\n",
    "posiciones_periodicas = [int(item.split('Datosb279')[1].split('.')[0]) for item in periodicas_variables]\n",
    "\n",
    "\n",
    "# Abre el archivo de texto en modo lectura\n",
    "with open('var_long', 'r') as file:\n",
    "    # Lee cada línea del archivo\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Inicializa una lista vacía para almacenar los elementos de la primera columna\n",
    "LPV = []\n",
    "periodos_LPV = []\n",
    "# Itera sobre cada línea del archivo\n",
    "for line in lines:\n",
    "    # Divide la línea en columnas separadas por un espacio en blanco\n",
    "    columnas = line.split()\n",
    "    # Añade el primer elemento (primera columna) a la lista primera_columna\n",
    "    LPV.append(columnas[0])\n",
    "    periodos_LPV.append(float(columnas[1]))\n",
    "    \n",
    "\n",
    "# Extraer los números después de \"Datosb279\" usando list comprehension\n",
    "posiciones_LPV = [int(item.split('Datosb279')[1].split('.')[0]) for item in LPV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129efb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save\n"
     ]
    }
   ],
   "source": [
    "Series_periodicas=[]\n",
    "HJD_periodicas=[]\n",
    "error_periodicas=[]\n",
    "Series_LPV=[]\n",
    "HJD_LPV=[]\n",
    "error_LPV=[]\n",
    "for k in posiciones_periodicas: \n",
    "    Series_periodicas.append(ks_nan[k])\n",
    "    HJD_periodicas.append(HJD_na[k])\n",
    "    error_periodicas.append(error_nan[k])\n",
    "for l in posiciones_LPV: \n",
    "    Series_LPV.append(ks_nan[l])\n",
    "    HJD_LPV.append(HJD_na[l])\n",
    "    error_LPV.append(error_nan[l])\n",
    "x=0\n",
    "while x < len(Series_periodicas): \n",
    "    Sp=Series_periodicas[x]\n",
    "    Pp=periodos_periodicas[x]\n",
    "    Datep=HJD_periodicas[x]\n",
    "    t_0p = Datep[0]\n",
    "    name= posiciones_periodicas[x]\n",
    "    # 3. Calcular la fase para cada punto de tus datos\n",
    "    fasep = ((Datep - t_0p) / Pp) - np.floor((Datep - t_0p) / Pp)\n",
    "    plt.scatter(fasep, Sp, s=10, c='blue', alpha=0.5)\n",
    "    plt.xlabel('Phase')\n",
    "    plt.ylabel('Ks')\n",
    "    # Invertir el eje y\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title('Light curve b2791'+ str(name))\n",
    "    # Muestra la leyenda con el período promedio\n",
    "    plt.legend(['Period= {:.2f} days'.format(Pp)])\n",
    "    plt.scatter(fasep + 1, Sp, s=10, c='blue', alpha=0.5)\n",
    "    plt.scatter(fasep + 2, Sp, s=10, c='blue', alpha=0.5)\n",
    "    # Guarda la gráfica en un archivo\n",
    "    plt.savefig('Light curve b2791'+str(name)+'.png')\n",
    "    plt.close()  # Cerrar la figura para evitar superposiciones\n",
    "    #plt.show()\n",
    "    x+=1\n",
    "y=0\n",
    "while y< len(Series_LPV):\n",
    "    S=Series_LPV[y]\n",
    "    P=periodos_LPV[y]\n",
    "    Date=HJD_LPV[y]\n",
    "    t_0 = Date[0]\n",
    "    name= posiciones_LPV[y]\n",
    "    # 3. Calcular la fase para cada punto de tus datos\n",
    "    fase = ((Date - t_0) / P) - np.floor((Date - t_0) / P)\n",
    "    plt.scatter(fase, S, s=10, c='blue', alpha=0.5)\n",
    "    plt.xlabel('Phase')\n",
    "    plt.ylabel('Ks')\n",
    "    # Invertir el eje y\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title('Light curve b2791'+ str(name))\n",
    "    # Muestra la leyenda con el período promedio\n",
    "    plt.legend(['Period= {:.2f} days'.format(P)])\n",
    "    plt.scatter(fase + 1, S, s=10, c='blue', alpha=0.5)\n",
    "    # Guarda la gráfica en un archivo\n",
    "    plt.savefig('Light curve b2791'+str(name)+'.png')\n",
    "    plt.close()  # Cerrar la figura para evitar superposiciones\n",
    "    #plt.show()\n",
    "    y+=1\n",
    "print(\"Save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1612caca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo FITS creado con éxito.\n"
     ]
    }
   ],
   "source": [
    "# Función para llenar las listas con NaNs para igualar la longitud\n",
    "\n",
    "def llenar_con_nan(lista, longitud_maxima):\n",
    "    return [np.pad(sublista, (0, longitud_maxima - len(sublista)), mode='constant', constant_values=np.nan) for sublista in lista]\n",
    "\n",
    "# Obtener la longitud máxima de todas las listas\n",
    "longitud_maxima = max(len(sublista) for sublista in HJD_periodicas + error_periodicas + Series_LPV + HJD_LPV + error_LPV)\n",
    "\n",
    "\n",
    "# Llenar las listas con NaNs para igualar la longitud\n",
    "Series_periodicas = llenar_con_nan(Series_periodicas, longitud_maxima)\n",
    "HJD_periodicas = llenar_con_nan(HJD_periodicas, longitud_maxima)\n",
    "error_periodicas = llenar_con_nan(error_periodicas, longitud_maxima)\n",
    "Series_LPV = llenar_con_nan(Series_LPV, longitud_maxima)\n",
    "HJD_LPV = llenar_con_nan(HJD_LPV, longitud_maxima)\n",
    "error_LPV = llenar_con_nan(error_LPV, longitud_maxima)\n",
    "\n",
    "# Convertir las listas de listas a arrays de NumPy\n",
    "Series_periodicas_array = np.array(Series_periodicas)\n",
    "HJD_periodicas_array = np.array(HJD_periodicas)\n",
    "error_periodicas_array = np.array(error_periodicas)\n",
    "Series_LPV_array = np.array(Series_LPV)\n",
    "HJD_LPV_array = np.array(HJD_LPV)\n",
    "error_LPV_array = np.array(error_LPV)\n",
    "\n",
    "# Crear un HDU primario con un header vacío\n",
    "primary_hdu = fits.PrimaryHDU()\n",
    "\n",
    "# Crear objetos ImageHDU para cada array\n",
    "hdu1 = fits.ImageHDU(Series_periodicas_array, name='S1_period')\n",
    "hdu2 = fits.ImageHDU(HJD_periodicas_array, name='HJD1_period')\n",
    "hdu3 = fits.ImageHDU(error_periodicas_array, name='E1_period')\n",
    "hdu4 = fits.ImageHDU(Series_LPV_array, name='S1_LPV')\n",
    "hdu5 = fits.ImageHDU(HJD_LPV_array, name='HJD1_LPV')\n",
    "hdu6 = fits.ImageHDU(error_LPV_array, name='E1_LPV')\n",
    "\n",
    "\n",
    "# Crear un HDUList y agregar los HDUs correspondientes\n",
    "hdul = fits.HDUList([primary_hdu, hdu1, hdu2, hdu3, hdu4, hdu5, hdu6])\n",
    "\n",
    "# Guardar el HDUList en un archivo FITS\n",
    "hdul.writeto('Variablesb279.fits', overwrite=True)\n",
    "\n",
    "print(\"Archivo FITS creado con éxito.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa2b443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
