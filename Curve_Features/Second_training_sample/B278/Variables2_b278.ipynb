{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6697a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from scipy.optimize import curve_fit\n",
    "from astropy.timeseries import LombScargle\n",
    "from scipy.signal import find_peaks\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "796d2900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: PVaribales_2b278.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       4   ()      \n",
      "  1  KS_ALE        1 ImageHDU         8   (66, 100000)   float64   \n",
      "  2  EKS_ALE       1 ImageHDU         8   (66, 100000)   float64   \n",
      "  3  MEANS_ALE     1 ImageHDU         7   (100000,)   float64   \n",
      "  4  STD_DEVS_ALE    1 ImageHDU         7   (100000,)   float64   \n",
      "  5  PV            1 ImageHDU         8   (66, 111)   float64   \n",
      "  6  EPV           1 ImageHDU         8   (66, 111)   float64   \n"
     ]
    }
   ],
   "source": [
    "archivo = fits.open('TCampob278.fits')\n",
    "archivo1 = fits.open('PVaribales_2b278.fits')\n",
    "HJD=archivo[1].data\n",
    "Error=archivo1[6].data\n",
    "Ks=archivo1[5].data\n",
    "archivo1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "304ff606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_nan(error, ks, HJD):\n",
    "    indices_validos = ~np.isnan(ks)\n",
    "    error_filtrado = [error[i] for i in range(len(ks)) if indices_validos[i]]\n",
    "    ks_filtrado = [ks[i] for i in range(len(ks)) if indices_validos[i]]\n",
    "    HJD_filtrado = [HJD[i] for i in range(len(ks)) if indices_validos[i]]\n",
    "    return error_filtrado, ks_filtrado, np.round(HJD_filtrado,8)\n",
    "\n",
    "ks_nan=[]\n",
    "error_nan=[]\n",
    "HJD_na=[]\n",
    "y=0\n",
    "while y<len(Ks):\n",
    "    error_filtrado, ks_filtrado, HJD_filtrado = eliminar_nan(Error[y], Ks[y], HJD-2400000)\n",
    "    ks_nan.append(ks_filtrado)\n",
    "    error_nan.append(error_filtrado)\n",
    "    HJD_na.append(HJD_filtrado)\n",
    "    y+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6fcacc",
   "metadata": {},
   "source": [
    "# Variables Periodicas y LPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ffc933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre el archivo de texto en modo lectura\n",
    "with open('2B278.txt', 'r') as file:\n",
    "    # Lee cada línea del archivo\n",
    "    lines = file.readlines()\n",
    "# Inicializa una lista vacía para almacenar los elementos de la primera columna\n",
    "posibles_variables = []\n",
    "\n",
    "# Itera sobre cada línea del archivo\n",
    "for line in lines:\n",
    "    # Divide la línea en columnas separadas por un espacio en blanco\n",
    "    columnas = line.split()\n",
    "    # Añade el primer elemento (primera columna) a la lista primera_columna\n",
    "    posibles_variables.append(columnas[0])\n",
    "\n",
    "    \n",
    "# Abre el archivo de texto en modo lectura\n",
    "with open('var_per', 'r') as file:\n",
    "    # Lee cada línea del archivo\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Inicializa una lista vacía para almacenar los elementos de la primera columna\n",
    "periodicas_variables = []\n",
    "periodos_periodicas = []\n",
    "# Itera sobre cada línea del archivo\n",
    "for line in lines:\n",
    "    # Divide la línea en columnas separadas por un espacio en blanco\n",
    "    columnas = line.split()\n",
    "    # Añade el primer elemento (primera columna) a la lista primera_columna\n",
    "    periodicas_variables.append(columnas[0])\n",
    "    periodos_periodicas.append(float(columnas[1]))\n",
    "    \n",
    "\n",
    "# Extraer los números después de \"Datosb278\" usando list comprehension\n",
    "posiciones_periodicas = [int(item.split('b278D')[1].split('.')[0]) for item in periodicas_variables]\n",
    "\n",
    "\n",
    "# Abre el archivo de texto en modo lectura\n",
    "with open('var_long', 'r') as file:\n",
    "    # Lee cada línea del archivo\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Inicializa una lista vacía para almacenar los elementos de la primera columna\n",
    "LPV = []\n",
    "periodos_LPV = []\n",
    "# Itera sobre cada línea del archivo\n",
    "for line in lines:\n",
    "    # Divide la línea en columnas separadas por un espacio en blanco\n",
    "    columnas = line.split()\n",
    "    # Añade el primer elemento (primera columna) a la lista primera_columna\n",
    "    LPV.append(columnas[0])\n",
    "    periodos_LPV.append(float(columnas[1]))\n",
    "    \n",
    "\n",
    "# Extraer los números después de \"Datosb278\" usando list comprehension\n",
    "posiciones_LPV = [int(item.split('b278D')[1].split('.')[0]) for item in LPV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eba0df3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save\n"
     ]
    }
   ],
   "source": [
    "Series_periodicas=[]\n",
    "HJD_periodicas=[]\n",
    "error_periodicas=[]\n",
    "Series_LPV=[]\n",
    "HJD_LPV=[]\n",
    "error_LPV=[]\n",
    "for k in posiciones_periodicas: \n",
    "    Series_periodicas.append(ks_nan[k])\n",
    "    HJD_periodicas.append(HJD_na[k])\n",
    "    error_periodicas.append(error_nan[k])\n",
    "for l in posiciones_LPV: \n",
    "    Series_LPV.append(ks_nan[l])\n",
    "    HJD_LPV.append(HJD_na[l])\n",
    "    error_LPV.append(error_nan[l])\n",
    "x=0\n",
    "while x < len(Series_periodicas): \n",
    "    Sp=Series_periodicas[x]\n",
    "    Pp=periodos_periodicas[x]\n",
    "    Datep=HJD_periodicas[x]\n",
    "    t_0p = Datep[0]\n",
    "    name= posiciones_periodicas[x]\n",
    "    # 3. Calcular la fase para cada punto de tus datos\n",
    "    fasep = ((Datep - t_0p) / Pp) - np.floor((Datep - t_0p) / Pp)\n",
    "    plt.scatter(fasep, Sp, s=10, c='blue', alpha=0.5)\n",
    "    plt.xlabel('Phase')\n",
    "    plt.ylabel('Ks')\n",
    "    # Invertir el eje y\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title('Light curve b2782'+ str(name))\n",
    "    # Muestra la leyenda con el período promedio\n",
    "    plt.legend(['Period= {:.2f} days'.format(Pp)])\n",
    "    plt.scatter(fasep + 1, Sp, s=10, c='blue', alpha=0.5)\n",
    "    plt.scatter(fasep + 2, Sp, s=10, c='blue', alpha=0.5)\n",
    "    # Guarda la gráfica en un archivo\n",
    "    plt.savefig('Light curve b2782'+str(name)+'.png')\n",
    "    plt.close()  # Cerrar la figura para evitar superposiciones\n",
    "    #plt.show()\n",
    "    x+=1\n",
    "y=0\n",
    "while y< len(Series_LPV):\n",
    "    S=Series_LPV[y]\n",
    "    P=periodos_LPV[y]\n",
    "    Date=HJD_LPV[y]\n",
    "    t_0 = Date[0]\n",
    "    name= posiciones_LPV[y]\n",
    "    # 3. Calcular la fase para cada punto de tus datos\n",
    "    fase = ((Date - t_0) / P) - np.floor((Date - t_0) / P)\n",
    "    plt.scatter(fase, S, s=10, c='blue', alpha=0.5)\n",
    "    plt.xlabel('Phase')\n",
    "    plt.ylabel('Ks')\n",
    "    # Invertir el eje y\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.title('Light curve b2782'+ str(name))\n",
    "    # Muestra la leyenda con el período promedio\n",
    "    plt.legend(['Period= {:.2f} days'.format(P)])\n",
    "    plt.scatter(fase + 1, S, s=10, c='blue', alpha=0.5)\n",
    "    # Guarda la gráfica en un archivo\n",
    "    plt.savefig('Light curve b2782'+str(name)+'.png')\n",
    "    plt.close()  # Cerrar la figura para evitar superposiciones\n",
    "    #plt.show()\n",
    "    y+=1\n",
    "print(\"Save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddb93c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrays agregados al archivo FITS existente.\n"
     ]
    }
   ],
   "source": [
    "# Función para llenar las listas con NaNs para igualar la longitud\n",
    "\n",
    "def llenar_con_nan(lista, longitud_maxima):\n",
    "    return [np.pad(sublista, (0, longitud_maxima - len(sublista)), mode='constant', constant_values=np.nan) for sublista in lista]\n",
    "\n",
    "# Obtener la longitud máxima de todas las listas\n",
    "longitud_maxima = max(len(sublista) for sublista in HJD_periodicas + error_periodicas + Series_LPV + HJD_LPV + error_LPV)\n",
    "\n",
    "\n",
    "# Llenar las listas con NaNs para igualar la longitud\n",
    "Series_periodicas = llenar_con_nan(Series_periodicas, longitud_maxima)\n",
    "HJD_periodicas = llenar_con_nan(HJD_periodicas, longitud_maxima)\n",
    "error_periodicas = llenar_con_nan(error_periodicas, longitud_maxima)\n",
    "Series_LPV = llenar_con_nan(Series_LPV, longitud_maxima)\n",
    "HJD_LPV = llenar_con_nan(HJD_LPV, longitud_maxima)\n",
    "error_LPV = llenar_con_nan(error_LPV, longitud_maxima)\n",
    "\n",
    "# Convertir las listas de listas a arrays de NumPy\n",
    "Series_periodicas_array = np.array(Series_periodicas)\n",
    "HJD_periodicas_array = np.array(HJD_periodicas)\n",
    "error_periodicas_array = np.array(error_periodicas)\n",
    "Series_LPV_array = np.array(Series_LPV)\n",
    "HJD_LPV_array = np.array(HJD_LPV)\n",
    "error_LPV_array = np.array(error_LPV)\n",
    "\n",
    "# Abrir el archivo FITS existente\n",
    "hdul = fits.open('Variablesb278.fits', mode=\"append\")\n",
    "\n",
    "\n",
    "# Crear objetos ImageHDU para cada array con sus respectivos nombres\n",
    "hdu7 = fits.ImageHDU(Series_periodicas_array, name='S2_period')\n",
    "hdu8 = fits.ImageHDU(HJD_periodicas_array, name='HJD2_period')\n",
    "hdu9 = fits.ImageHDU(error_periodicas_array, name='HJD2_period')\n",
    "hdu10 = fits.ImageHDU(Series_LPV_array, name='S2_LPV')\n",
    "hdu11 = fits.ImageHDU(HJD_LPV_array, name='HJD2_LPV')\n",
    "hdu12 = fits.ImageHDU(error_LPV_array, name='E2_LPV')\n",
    "\n",
    "# Agregar los HDUs al HDUList existente\n",
    "hdul.append(hdu7)\n",
    "hdul.append(hdu8)\n",
    "hdul.append(hdu9)\n",
    "hdul.append(hdu10)\n",
    "hdul.append(hdu11)\n",
    "hdul.append(hdu12)\n",
    "\n",
    "# Guardar el HDUList actualizado en el mismo archivo FITS\n",
    "#hdul.writeto('Variablesb278.fits', overwrite=True)\n",
    "hdul.close()\n",
    "print(\"Arrays agregados al archivo FITS existente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6258dfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: Variablesb278.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU       4   ()      \n",
      "  1  S1_PERIOD     1 ImageHDU         8   (66, 15)   float64   \n",
      "  2  HJD1_PERIOD    1 ImageHDU         8   (66, 15)   float64   \n",
      "  3  E1_PERIOD     1 ImageHDU         8   (66, 15)   float64   \n",
      "  4  S1_LPV        1 ImageHDU         8   (66, 1)   float64   \n",
      "  5  HJD1_LPV      1 ImageHDU         8   (66, 1)   float64   \n",
      "  6  E1_LPV        1 ImageHDU         8   (66, 1)   float64   \n",
      "  7  S2_PERIOD     1 ImageHDU         8   (66, 25)   float64   \n",
      "  8  HJD2_PERIOD    1 ImageHDU         8   (66, 25)   float64   \n",
      "  9  HJD2_PERIOD    1 ImageHDU         8   (66, 25)   float64   \n",
      " 10  S2_LPV        1 ImageHDU         8   (66, 3)   float64   \n",
      " 11  HJD2_LPV      1 ImageHDU         8   (66, 3)   float64   \n",
      " 12  E2_LPV        1 ImageHDU         8   (66, 3)   float64   \n"
     ]
    }
   ],
   "source": [
    "archivo2 = fits.open('Variablesb278.fits')\n",
    "archivo2.info()\n",
    "archivo2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd7211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
