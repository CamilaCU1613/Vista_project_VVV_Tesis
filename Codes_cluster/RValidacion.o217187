Requirement already satisfied: statsmodels in ./.conda/envs/Tesis3/lib/python3.9/site-packages (0.14.2)
Requirement already satisfied: numpy>=1.22.3 in ./.local/lib/python3.9/site-packages (from statsmodels) (1.23.0)
Requirement already satisfied: scipy!=1.9.2,>=1.8 in ./.local/lib/python3.9/site-packages (from statsmodels) (1.8.0)
Requirement already satisfied: pandas!=2.1.0,>=1.4 in ./.conda/envs/Tesis3/lib/python3.9/site-packages (from statsmodels) (2.2.2)
Requirement already satisfied: patsy>=0.5.6 in ./.conda/envs/Tesis3/lib/python3.9/site-packages (from statsmodels) (0.5.6)
Requirement already satisfied: packaging>=21.3 in ./.conda/envs/Tesis3/lib/python3.9/site-packages (from statsmodels) (24.0)
Requirement already satisfied: python-dateutil>=2.8.2 in ./.conda/envs/Tesis3/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)
Requirement already satisfied: pytz>=2020.1 in ./.conda/envs/Tesis3/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)
Requirement already satisfied: tzdata>=2022.7 in ./.conda/envs/Tesis3/lib/python3.9/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)
Requirement already satisfied: six in ./.conda/envs/Tesis3/lib/python3.9/site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)
Requirement already satisfied: pyyaml in ./.conda/envs/Tesis3/lib/python3.9/site-packages (6.0.1)
Requirement already satisfied: scikit-learn in ./.conda/envs/Tesis3/lib/python3.9/site-packages (1.4.2)
Requirement already satisfied: numpy>=1.19.5 in ./.local/lib/python3.9/site-packages (from scikit-learn) (1.23.0)
Requirement already satisfied: scipy>=1.6.0 in ./.local/lib/python3.9/site-packages (from scikit-learn) (1.8.0)
Requirement already satisfied: joblib>=1.2.0 in ./.conda/envs/Tesis3/lib/python3.9/site-packages (from scikit-learn) (1.4.2)
Requirement already satisfied: threadpoolctl>=2.0.0 in ./.conda/envs/Tesis3/lib/python3.9/site-packages (from scikit-learn) (3.5.0)
Soy un JOB de prueba
Corri en la maquina: nodea-6
Corri el: nodea-6
Ejecutando Script de python 

importe las liberias
Filename: Features
No.    Name      Ver    Type      Cards   Dimensions   Format
  0  PRIMARY       1 PrimaryHDU       4   ()      
  1  8_VKS         1 ImageHDU         8   (66, 267)   float64   
  2  8_NVKS        1 ImageHDU         8   (66, 300)   float64   
  3  8_HJD         1 ImageHDU         7   (66,)   float64   
  4  9_NVKS        1 ImageHDU         8   (68, 350)   float64   
  5  9_HJD         1 ImageHDU         7   (68,)   float64   
  6  9_VKS         1 ImageHDU         8   (68, 341)   float64   
/hpcfs/home/fisica/c.cardenasu/Cluster_b7978.py:627: RuntimeWarning: invalid value encountered in double_scalars
  ruld_sum = sum([((Y[i] - Y[i + 1]) / abs(Y[i] - Y[i + 1])) * (X[i + 1] - X[i]) for i in range(N - 1)])
/hpcfs/home/fisica/c.cardenasu/Cluster_b7978.py:55: RuntimeWarning: Mean of empty slice
  media = np.nanmean(lista)
/hpcfs/home/fisica/c.cardenasu/.local/lib/python3.9/site-packages/numpy/lib/nanfunctions.py:1878: RuntimeWarning: Degrees of freedom <= 0 for slice.
  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,
608
650
Cantidad de objetos en s_novariables antes de la superposición: 0
Termine MAD
608
650
Cantidad de objetos en s_novariables antes de la superposición: 0
Termine Mean
608
650
Cantidad de objetos en s_novariables antes de la superposición: 0
Termine VART
608
650
Cantidad de objetos en s_novariables antes de la superposición: 0
Termine AV
608
650
Cantidad de objetos en s_novariables antes de la superposición: 18
Termine robAbbe
608
650
Cantidad de objetos en s_novariables antes de la superposición: 0
Termine DIFDER
608
650
Cantidad de objetos en s_novariables antes de la superposición: 4
Termine Proy2
608
650
Cantidad de objetos en s_novariables antes de la superposición: 0
Termine integral
608
650
Cantidad de objetos en s_novariables antes de la superposición: 0
Termine RULD
608
650
Cantidad de objetos en s_novariables antes de la superposición: 0
Termine Os
608
650
Cantidad de objetos en s_novariables antes de la superposición: 1
Termine rEucliDs
608
650
Cantidad de objetos en s_novariables antes de la superposición: 0
Termine Low
608
650
Cantidad de objetos en s_novariables antes de la superposición: 0
Termine row
608
650
Cantidad de objetos en s_novariables antes de la superposición: 0
Termine Delta
608
650
Cantidad de objetos en s_novariables antes de la superposición: 4
Termine Slpe
608
650
Cantidad de objetos en s_novariables antes de la superposición: 1
Termine min sople
608
650
Cantidad de objetos en s_novariables antes de la superposición: 1
Termine r_value
608
650
Cantidad de objetos en s_novariables antes de la superposición: 173
Termine min rvalue
608
650
Cantidad de objetos en s_novariables antes de la superposición: 0
Termine ETA
[-1.03896471  0.          0.          0.         -1.03896471  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.96923553  0.
 -1.03896471  0.          0.          0.          0.          0.
  0.96923553  0.          0.          0.          0.          0.96923553
 -1.03896471 -1.03896471  0.          0.          0.          0.
  0.         -1.03896471  0.          0.          0.          0.96923553
 -1.03896471  0.          0.          0.96923553  0.96923553  0.
  0.          0.96923553  0.          0.          0.96923553  0.
 -1.03896471  0.          0.          0.          0.          0.
  0.         -1.03896471  0.         -1.03896471  0.96923553 -1.03896471
 -1.03896471  0.96923553  0.          0.          0.          0.
  0.          0.         -1.03896471  0.         -1.03896471  0.
  0.          0.          0.96923553  0.          0.          0.
  0.          0.96923553  0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.96923553
  0.         -1.03896471  0.          0.          0.96923553  0.
  0.96923553  0.96923553  0.          0.          0.          0.
  0.96923553 -1.03896471  0.          0.          0.         -1.03896471
 -1.03896471  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -1.03896471  0.          0.          0.
  0.          0.          0.          0.          0.         -1.03896471
  0.          0.96923553 -1.03896471  0.         -1.03896471  0.
 -1.03896471  0.          0.          0.          0.          0.
  0.          0.         -1.03896471  0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.96923553  0.          0.
  0.          0.          0.96923553  0.96923553  0.          0.96923553
  0.          0.          0.96923553  0.96923553  0.96923553  0.
  0.96923553  0.          0.          0.         -1.03896471  0.
 -1.03896471 -1.03896471  0.          0.          0.          0.
  0.          0.          0.          0.          0.96923553  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.96923553  0.         -1.03896471
  0.          0.96923553  0.          0.          0.          0.
 -1.03896471 -1.03896471 -1.03896471 -1.03896471  0.          0.96923553
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.96923553  0.          0.         -0.03486459  0.          0.
  0.         -1.03896471  0.         -1.03896471  0.          0.
  0.          0.          0.96923553  0.          0.         -1.03896471
  0.          0.          0.          0.          0.96923553  0.
  0.          0.          0.          0.          0.          0.
  0.96923553  0.96923553  0.96923553  0.          0.96923553  0.
  0.          0.96923553  0.96923553  0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.         -1.03896471  0.          0.96923553  0.          0.
  0.          0.          0.          0.          0.         -1.03896471
  0.          0.         -1.03896471  0.          0.96923553  0.96923553
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.96923553  0.96923553  0.
 -1.03896471  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.         -1.03896471  0.          0.96923553
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.96923553
 -1.03896471  0.          0.          0.96923553  0.          0.
  0.          0.          0.96923553  0.          0.          0.
  0.96923553 -1.03896471  0.          0.          0.          0.
 -1.03896471 -1.03896471 -1.03896471 -1.03896471  0.          0.
  0.          0.          0.          0.          0.          0.96923553
  0.          0.          0.96923553  0.          0.          0.
 -1.03896471  0.96923553  0.          0.          0.          0.96923553
  0.          0.          0.          0.          0.          0.
  0.          0.96923553  0.96923553  0.          0.          0.
  0.         -1.03896471  0.          0.          0.          0.96923553
 -1.03896471  0.          0.          0.          0.          0.
  0.          0.          0.          0.         -1.03896471  0.
  0.          0.          0.96923553  0.          0.          0.
  0.          0.          0.96923553  0.          0.          0.
 -1.03896471  0.         -1.03896471  0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.96923553  0.          0.          0.96923553  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.96923553
  0.96923553  0.          0.          0.          0.          0.
  0.          0.          0.          0.         -1.03896471  0.
  0.          0.          0.          0.          0.96923553  0.96923553
  0.96923553  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.96923553  0.96923553  0.          0.          0.
  0.          0.          0.         -1.03896471 -1.03896471  0.
  0.         -1.03896471 -1.03896471  0.         -1.03896471 -1.03896471
  0.          0.96923553 -1.03896471 -1.03896471  0.         -1.03896471
  0.          0.          0.          0.          0.          0.
  0.96923553  0.          0.96923553  0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -1.03896471  0.          0.          0.
 -1.03896471  0.          0.          0.          0.96923553  0.
  0.          0.         -1.03896471  0.          0.96923553  0.
  0.          0.          0.          0.96923553  0.          0.
  0.          0.          0.         -1.03896471  0.          0.96923553
  0.          0.         -1.03896471  0.          0.          0.
  0.          0.          0.          0.          0.         -1.03896471
  0.         -1.03896471]
[ 0.          0.          0.          0.          0.          0.
  0.         -1.75408666 -1.75408666  0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -1.75408666  0.          0.          0.
  0.          0.         -1.75408666  0.          0.          0.
  0.          0.          0.61287365  0.          0.          0.
  0.          0.61287365  0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -1.75408666
  0.          0.          0.          0.          0.          0.
  0.61287365  0.          0.          0.          0.          0.61287365
  0.61287365  0.          0.          0.         -1.75408666  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.61287365  0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.61287365  0.          0.61287365  0.          0.
  0.61287365  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.         -1.75408666  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.61287365  0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.         -1.75408666  0.
  0.          0.          0.          0.          0.          0.
  0.          0.61287365  0.          0.          0.          0.
  0.          0.          0.          0.          0.61287365  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.61287365  0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.         -1.75408666  0.          0.61287365
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.61287365  0.          0.          0.
  0.          0.          0.          0.          0.61287365  0.
  0.          0.          0.          0.          0.          0.
 -1.75408666  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.61287365  0.          0.          0.
  0.          0.          0.          0.61287365  0.          0.
  0.          0.          0.61287365  0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.61287365  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
 -1.75408666  0.          0.          0.          0.          0.
  0.          0.61287365  0.          0.          0.          0.
 -0.5706065   0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.61287365  0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.61287365  0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.         -1.75408666
  0.          0.          0.          0.61287365  0.          0.
  0.          0.          0.          0.          0.          0.61287365
  0.          0.          0.          0.          0.          0.
  0.          0.61287365  0.          0.          0.          0.
  0.          0.61287365  0.          0.          0.          0.
  0.          0.61287365  0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.61287365  0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.         -1.75408666  0.          0.          0.          0.
  0.          0.          0.          0.         -0.5706065   0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.61287365  0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.61287365  0.61287365  0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.61287365  0.          0.61287365  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.61287365  0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.61287365
  0.          0.          0.          0.          0.          0.
  0.          0.          0.61287365  0.          0.          0.
  0.          0.61287365  0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.61287365  0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.         -0.5706065   0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.          0.
  0.          0.          0.          0.          0.61287365  0.
  0.          0.        ]
Cantidad de objetos en s_novariables antes de la superposición: 13
Termine reDSing
608
650
Cantidad de objetos en s_novariables antes de la superposición: 0
Termine rbLeon
608
650
Cantidad de objetos en s_novariables antes de la superposición: 18
Termine rbsing
llegue a H20
Checking whether there is an H2O instance running at http://localhost:54321..... not found.
Attempting to start a local H2O server...
  Java Version: openjdk version "1.8.0_152-release"; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode)
  Starting server from /hpcfs/home/fisica/c.cardenasu/.local/lib/python3.9/site-packages/h2o/backend/bin/h2o.jar
  Ice root: /tmp/tmpedp7b67y
  JVM stdout: /tmp/tmpedp7b67y/h2o_c_cardenasu_started_from_python.out
  JVM stderr: /tmp/tmpedp7b67y/h2o_c_cardenasu_started_from_python.err
  Server is running at http://127.0.0.1:54321
Connecting to H2O server at http://127.0.0.1:54321 ... successful.
--------------------------  ----------------------------------
H2O_cluster_uptime:         09 secs
H2O_cluster_timezone:       America/Bogota
H2O_data_parsing_timezone:  UTC
H2O_cluster_version:        3.46.0.1
H2O_cluster_version_age:    1 month and 29 days
H2O_cluster_name:           H2O_from_python_c_cardenasu_pfjn72
H2O_cluster_total_nodes:    1
H2O_cluster_free_memory:    26.62 Gb
H2O_cluster_total_cores:    8
H2O_cluster_allowed_cores:  8
H2O_cluster_status:         locked, healthy
H2O_connection_url:         http://127.0.0.1:54321
H2O_connection_proxy:       {"http": null, "https": null}
H2O_internal_security:      False
Python_version:             3.9.0 final
--------------------------  ----------------------------------
Concatenar
Se han transcrito las variables a formato H2O
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |/hpcfs/home/fisica/c.cardenasu/.local/lib/python3.9/site-packages/h2o/frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install datatable (for Python 3.9 or lower), or polars and pyarrow (for Python 3.10 or above) and activate it using:

with h2o.utils.threading.local_context(polars_enabled=True, datatable_enabled=True):
    pandas_df = h2o_df.as_data_frame()

  warnings.warn("Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using"
/hpcfs/home/fisica/c.cardenasu/.local/lib/python3.9/site-packages/h2o/estimators/estimator_base.py:192: RuntimeWarning: Dropping bad and constant columns: [resultados_DeltaM]
  warnings.warn(mesg["message"], RuntimeWarning)
████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
se ha creado el frame de H2O
se ha calculado la matriz de correlacion
drf Model Build progress: |████████████████████████████████████/hpcfs/home/fisica/c.cardenasu/Cluster_b7978.py:1844: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored
  plt.scatter(componentes[:, 0], componentes[:, 1], cmap='viridis')
██████████████████| (done) 100%
ModelMetricsBinomial: drf
** Reported on test data. **

MSE: 0.03243096818168785
RMSE: 0.180086002181424
LogLoss: 0.1469414704248839
Mean Per-Class Error: 0.019435351882160393
AUC: 0.9980360065466449
AUCPR: 0.9977956079390734
Gini: 0.9960720130932899

Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.42097851336002345
             No_variable    Variable    Error    Rate
-----------  -------------  ----------  -------  ------------
No_variable  251            9           0.0346   (9.0/260.0)
Variable     1              234         0.0043   (1.0/235.0)
Total        252            243         0.0202   (10.0/495.0)

Maximum Metrics: Maximum metrics at their respective thresholds
metric                       threshold    value     idx
---------------------------  -----------  --------  -----
max f1                       0.420979     0.979079  178
max f2                       0.420979     0.989011  178
max f0point5                 0.597434     0.981755  164
max accuracy                 0.458648     0.979798  174
max precision                1            1         0
max recall                   0.372727     1         186
max specificity              1            1         0
max absolute_mcc             0.420979     0.960061  178
max min_per_class_accuracy   0.494356     0.976923  171
max mean_per_class_accuracy  0.420979     0.980565  178
max tns                      1            260       0
max fns                      1            229       0
max fps                      0            260       379
max tps                      0.372727     235       186
max tnr                      1            1         0
max fnr                      1            0.974468  0
max fpr                      0            1         379
max tpr                      0.372727     1         186

Gains/Lift Table: Avg response rate: 47.47 %, avg score: 48.79 %
group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score      cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain    kolmogorov_smirnov
-------  --------------------------  -----------------  ---------  -----------------  ---------------  ---------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------  --------------------
1        0.0121212                   1                  2.10638    2.10638            1                1          1                           1                   0.0255319       0.0255319                  110.638   110.638            0.0255319
2        0.030303                    0.995              2.10638    2.10638            1                0.99547    1                           0.997282            0.0382979       0.0638298                  110.638   110.638            0.0638298
3        0.030303                    0.994369           0          2.10638            0                0          1                           0.997282            0               0.0638298                  -100      110.638            0.0638298
4        0.0484848                   0.99               2.10638    2.10638            1                0.99179    1                           0.995222            0.0382979       0.102128                   110.638   110.638            0.102128
5        0.0505051                   0.988722           2.10638    2.10638            1                0.989075   1                           0.994977            0.00425532      0.106383                   110.638   110.638            0.106383
6        0.107071                    0.975              2.10638    2.10638            1                0.981375   1                           0.987791            0.119149        0.225532                   110.638   110.638            0.225532
7        0.151515                    0.956366           2.10638    2.10638            1                0.965675   1                           0.981303            0.093617        0.319149                   110.638   110.638            0.319149
8        0.2                         0.944713           2.10638    2.10638            1                0.94935    1                           0.973557            0.102128        0.421277                   110.638   110.638            0.421277
9        0.30101                     0.896985           2.10638    2.10638            1                0.919462   1                           0.955404            0.212766        0.634043                   110.638   110.638            0.634043
10       0.4                         0.775758           2.10638    2.10638            1                0.84527    1                           0.928149            0.208511        0.842553                   110.638   110.638            0.842553
11       0.50101                     0.380263           1.5166     1.98747            0.72             0.611275   0.943548                    0.864263            0.153191        0.995745                   51.6596   98.7474            0.941899
12       0.6                         0.209978           0.0429874  1.66667            0.0204082        0.276767   0.791246                    0.767336            0.00425532      1                          -95.7013  66.6667            0.761538
13       0.69899                     0.112438           0          1.43064            0                0.155079   0.679191                    0.680629            0               1                          -100      43.0636            0.573077
14       0.8                         0.0494223          0          1.25               0                0.0761701  0.593434                    0.604309            0               1                          -100      25                 0.380769
15       0.89899                     0.0213995          0          1.11236            0                0.0341888  0.52809                     0.541531            0               1                          -100      11.236             0.192308
16       1                           0                  0          1                  0                0.0105596  0.474747                    0.487898            0               1                          -100      0                  0

Importancias relativas de las características de entrenamiento:
                  variable  relative_importance  scaled_importance  percentage
0     resultados_slope_min          6310.862793           1.000000    0.237264
1                     proy          3624.792236           0.574373    0.136278
2                integrals          3411.512451           0.540578    0.128260
3   resultados_r_value_min          2753.790039           0.436357    0.103532
4                    rob_s          1561.721558           0.247466    0.058715
5               resultados          1385.634766           0.219563    0.052094
6                 rEucliDs          1262.179688           0.200001    0.047453
7                   VART_s           965.466553           0.152985    0.036298
8                     mads           872.761780           0.138295    0.032812
9                       os           871.628906           0.138116    0.032770
10      resultados_r_value           712.654785           0.112925    0.026793
11                    av_s           540.899170           0.085709    0.020336
12                   rulds           510.491608           0.080891    0.019193
13  resultados_rbLeon_sign           428.020935           0.067823    0.016092
14                  random           417.376709           0.066136    0.015692
15      resultados_reDSign           310.931244           0.049269    0.011690
16                DIFDER_s           157.082382           0.024891    0.005906
17        resultados_slope           128.728912           0.020398    0.004840
18          resultados_low            98.362061           0.015586    0.003698
19       resultados_rbLeon            96.707588           0.015324    0.003636
20          resultados_eta            95.135727           0.015075    0.003577
21          resultados_row            81.752594           0.012954    0.003074
Cargas Factoriales:
   resultados_slope_min      proy  integrals  ...     rob_s   resultados  rEucliDs
0              0.124555  0.058954   0.220501  ...  0.618292     0.721399  0.490693
1             -0.542968  0.040321  -0.172016  ...  0.324780     0.369448 -0.564022

[2 rows x 7 columns]
finalice el Clustering
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
1258
<class 'list'>
<class 'list'>
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
se creo el frame
drf Model Build progress: |█████████████████████████████████████████████████████WARNING: File may have been truncated: actual file length (2554920960) is smaller than the expected size (2621206080) [astropy.io.fits.file]
█| (done) 100%
Accuracy: [[0.55525, 0.9817708333333334]]
F1 Score: [[0.55525, 0.9811320754716981]]
Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.55525
             No_variable    Variable    Error    Rate
-----------  -------------  ----------  -------  -----------
No_variable  195            0           0        (0.0/195.0)
Variable     7              182         0.037    (7.0/189.0)
Total        202            182         0.0182   (7.0/384.0)
Filename: Medias-Desviacion278.fits
No.    Name      Ver    Type      Cards   Dimensions   Format
  0  PRIMARY       1 PrimaryHDU       4   ()      
  1  MEDIAS        1 ImageHDU         7   (1260548,)   float64   
  2  MAD           1 ImageHDU         7   (1260548,)   float64   
  3  KS_NSAT       1 ImageHDU         8   (66, 1202504)   float64   
  4  EKS_NSAT      1 ImageHDU         8   (66, 1202504)   float64   
  5  MEDIASNS      1 ImageHDU         7   (1202504,)   float64   
  6  MADNS         1 ImageHDU         7   (1202504,)   float64   
  7  Q3_KS         1 ImageHDU         8   (66, 933459)   float64   
  8  Q3_EKS        1 ImageHDU         8   (66, 933459)   float64   
  9  D3_KS         1 ImageHDU         8   (66, 308874)   float64   
 10  D3_EKS        1 ImageHDU         8   (66, 308874)   float64   
Filename: Medias-Desviacion279.fits
No.    Name      Ver    Type      Cards   Dimensions   Format
  0  PRIMARY       1 PrimaryHDU       4   ()      
  1  MEDIAS        1 ImageHDU         7   (1280954,)   float64   
  2  MAD           1 ImageHDU         7   (1280954,)   float64   
  3  KS_NSAT       1 ImageHDU         8   (68, 1223069)   float64   
  4  EKS_NSAT      1 ImageHDU         8   (68, 1223069)   float64   
  5  MEDIASNS      1 ImageHDU         7   (1223069,)   float64   
  6  MADNS         1 ImageHDU         7   (1223069,)   float64   
  7  Q3_EKS        1 ImageHDU         8   (68, 956867)   float64   
  8  Q3_KS         1 ImageHDU         8   (68, 956867)   float64   
  9  EQ3_EKS       1 ImageHDU         8   (68, 956867)   float64   
 10  D3_KS         1 ImageHDU         8   (68, 306755)   float64   
 11  ED3_EKS       1 ImageHDU         8   (68, 306755)   float64   
615629
<class 'numpy.ndarray'>
615629
<class 'numpy.ndarray'>
615629
<class 'numpy.ndarray'>
615629
<class 'numpy.ndarray'>
615629
<class 'list'>
615629
<class 'numpy.ndarray'>
615629
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
615629
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
615629
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
615629
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
615629
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
615629
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
615629
Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%
se ha creado el frame de H2O
drf Model Build progress: |██████████████████████████████████████████████████████| (done) 100%
llegue a predicion
drf prediction progress: |██████/hpcfs/home/fisica/c.cardenasu/.local/lib/python3.9/site-packages/h2o/job.py:81: UserWarning: Test/Validation dataset is missing column ' resultados': substituting in a column of NaN
  warnings.warn(w)
█████████████████████████████████████████████████| (done) 100%
predije
Traceback (most recent call last):
  File "/hpcfs/home/fisica/c.cardenasu/Cluster_b7978.py", line 2313, in <module>
    if valor in recuentos:
TypeError: unhashable type: 'H2OFrame'
Closing connection _sid_9dda at exit
H2O session _sid_9dda closed.
Finalice la ejecucion del script 

